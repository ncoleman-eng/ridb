{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8e83eb2-f1ac-4ef1-bb9f-ac3ca13f837c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Poll API and Write to Bronze.Facilities"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, when, col\n",
    "import requests, time\n",
    "from pyspark.sql.types import StringType\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "catalog_name = \"dev_ridb\"\n",
    "schema_name = \"bronze\"\n",
    "table_name = \"facilities\"\n",
    "api_key = dbutils.secrets.get(scope=\"ridb_secrets\", key=\"apikey\")\n",
    "api_url = \"https://ridb.recreation.gov/api/v1/facilities\"\n",
    "page_size = 50\n",
    "delay_seconds = 0.025\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "def get_page(offset):\n",
    "    params = {\"limit\": page_size, \"offset\": offset}\n",
    "    headers = {\"accept\": \"application/json\", \"apikey\": api_key}\n",
    "    response = requests.get(api_url, headers=headers, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"API error: {response.status_code} - {response.text}\")\n",
    "    return response.json().get(\"RECDATA\", [])\n",
    "\n",
    "# Fetch loop\n",
    "all_records = []\n",
    "offset = 0\n",
    "while True:\n",
    "    data = get_page(offset)\n",
    "    print(f\"Fetched offset {offset} with {len(data)} records\")\n",
    "    if not data:\n",
    "        break\n",
    "    all_records.extend(data)\n",
    "    offset += page_size  # increment by 50\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "print(f\"Total records fetched: {len(all_records)}\")\n",
    "\n",
    "# Serialize any nested or mixed-type fields to JSON text\n",
    "for record in all_records:\n",
    "    for k, v in record.items():\n",
    "        if isinstance(v, (dict, list)):\n",
    "            record[k] = json.dumps(v)\n",
    "        elif isinstance(v, (int, float)):   # normalize numeric types to string\n",
    "            record[k] = str(v)\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(all_records)\n",
    "\n",
    "for c in df.columns:\n",
    "    df = df.withColumn(c, when(col(c) == \"\", None).otherwise(col(c)))\n",
    "\n",
    "df = df.withColumn(\"ingested_at\", current_timestamp())\n",
    "\n",
    "table_path = f\"{catalog_name}.{schema_name}.{table_name}\"\n",
    "\n",
    "if not spark.catalog.tableExists(table_path):\n",
    "    df.write.format(\"delta\") \\\n",
    "        .option(\"delta.enableChangeDataFeed\", \"true\") \\\n",
    "        .saveAsTable(table_path)\n",
    "else:\n",
    "    df.createOrReplaceTempView(\"staging_facilities\")\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {table_path} t\n",
    "        USING staging_facilities s\n",
    "        ON t.FacilityID = s.FacilityID AND t.LastUpdatedDate = s.LastUpdatedDate\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16102b46-184f-451a-b279-161b485858b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93b6383d-3419-4116-862d-235e238b3748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM dev_ridb.bronze.facilities\n",
    "WHERE facilityname IN (\n",
    "  SELECT facilityname\n",
    "  FROM dev_ridb.bronze.facilities\n",
    "  GROUP BY facilityname\n",
    "  HAVING COUNT(*) > 1\n",
    "  )\n",
    "  ORDER BY facilityname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f1ec74f-ae71-4694-9983-ac0a4232fd34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM dev_ridb.bronze.facilities ORDER BY rand() limit 5000"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7614284234629321,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze-Facilities",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
